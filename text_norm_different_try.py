import unicodedata

s = 'ğ‘¹ğ’ğ’•ğ’†ğ’'
s = 'ğ“—Ã«â“ğ•á´'
from confusables import normalize

def normalize_compatibily(s):
    return unicodedata.normalize('NFKD', s)

def remove_accents(s):
    return ''.join(c for c in unicodedata.normalize('NFD', s)
                   if unicodedata.category(c).startswith('L'))

print(s)
s = normalize_compatibily(s)
print(s)
s = remove_accents(s)
print(s)
# Test cases
test_cases = [
    ("ğ“£ğ“®ğ“¼ğ“½ ğ“’ğ“ªğ“¼ğ“®", "Test Case"),
    ("ğ•‹ğ•–ğ•¤ğ•¥ â„‚ğ•’ğ•¤ğ•–", "Test Case"),
    ("ï¼´ï½…ï½“ï½” ï¼£ï½ï½“ï½…", "Test Case"),
    ("êª»ê«€á¦“êª» á¥´êª–á¦“ê«€", "test case"),
    ("á´›á´‡êœ±á´› á´„á´€êœ±á´‡", "test case"),
    ("ğŸ‡¹â€‹â€‹ğŸ‡ªâ€‹â€‹ğŸ‡¸â€‹â€‹ğŸ‡¹â€‹ ğŸ‡¨â€‹â€‹ğŸ‡¦â€‹â€‹ğŸ‡¸â€‹â€‹ğŸ‡ª", "TEST CASE"),
    ("Tâƒâ€¯  â€¯eâƒâ€¯  â€¯sâƒâ€¯  â€¯tâƒ â€¯  â€¯Câƒâ€¯  â€¯aâƒâ€¯  â€¯sâƒâ€¯  â€¯eâƒ", "Test Case"),
    ("ğŸ…ƒğŸ„´ğŸ…ƒ ğŸ„²ğŸ„°ğŸ……ğŸ…ƒ ğŸ„²ğŸ„°ğŸ…‚ğŸ„´", "TEST CASE"),
    ("ğ—§ğ—²ğ˜€ğ˜ ğ—–ğ—®ğ˜€ğ—²", "Test Case"),
    ("ğ“ğğ¬ğ­ ğ‚ğšğ¬ğ", "Test Case"),
    ("ğ™ğ™šğ™¨ğ™© ğ˜¾ğ™–ğ™¨ğ™š", "Test Case"),
    ("ğ˜›ğ˜¦ğ˜´ğ˜µ ğ˜Šğ˜¢ğ˜´ğ˜¦", "Test Case"),
    ("ğšƒğšğššğš ğš‚ğšŠğšœğš", "Test Case"),
    ("ï¼´ï½…ï½“ï½”ã€€ï¼£ï½ï½“ï½…", "Test Case")
]

for text, expected_output in test_cases:
    result = normalize(text, prioritize_alpha=True)
    result = normalize_compatibily(result[0])
    result = remove_accents(result)


    print(f"Original: {text}")
    print(f"Normalized: {result}")
    print(f"Expected: {expected_output}")
    print(f"Pass: {result == expected_output}")
    print()
